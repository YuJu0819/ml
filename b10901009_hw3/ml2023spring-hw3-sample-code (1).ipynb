{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "799b20a4",
   "metadata": {
    "papermill": {
     "duration": 0.006786,
     "end_time": "2023-03-26T13:57:05.321099",
     "exception": false,
     "start_time": "2023-03-26T13:57:05.314313",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## HW3 Image Classification\n",
    "#### Solve image classification with convolutional neural networks(CNN).\n",
    "#### If you have any questions, please contact the TAs via TA hours, NTU COOL, or email to mlta-2023-spring@googlegroups.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d70b3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:57:05.334775Z",
     "iopub.status.busy": "2023-03-26T13:57:05.333660Z",
     "iopub.status.idle": "2023-03-26T13:57:06.329949Z",
     "shell.execute_reply": "2023-03-26T13:57:06.328698Z"
    },
    "papermill": {
     "duration": 1.005831,
     "end_time": "2023-03-26T13:57:06.332586",
     "exception": false,
     "start_time": "2023-03-26T13:57:05.326755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar 26 13:57:06 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\r\n",
      "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# check GPU type.\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d605f28e",
   "metadata": {
    "papermill": {
     "duration": 0.005485,
     "end_time": "2023-03-26T13:57:06.344023",
     "exception": false,
     "start_time": "2023-03-26T13:57:06.338538",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "836003f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:57:06.357736Z",
     "iopub.status.busy": "2023-03-26T13:57:06.356168Z",
     "iopub.status.idle": "2023-03-26T13:57:06.362301Z",
     "shell.execute_reply": "2023-03-26T13:57:06.361354Z"
    },
    "papermill": {
     "duration": 0.014759,
     "end_time": "2023-03-26T13:57:06.364272",
     "exception": false,
     "start_time": "2023-03-26T13:57:06.349513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_exp_name = \"sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b47d4c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:57:06.378314Z",
     "iopub.status.busy": "2023-03-26T13:57:06.376740Z",
     "iopub.status.idle": "2023-03-26T13:57:08.915722Z",
     "shell.execute_reply": "2023-03-26T13:57:08.914699Z"
    },
    "papermill": {
     "duration": 2.548373,
     "end_time": "2023-03-26T13:57:08.918280",
     "exception": false,
     "start_time": "2023-03-26T13:57:06.369907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from PIL import Image\n",
    "# from autoaugment import ImageNetPolicy\n",
    "import torchvision.models as models\n",
    "# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\n",
    "from torchvision.datasets import DatasetFolder, VisionDataset\n",
    "# This is for the progress bar.\n",
    "# from tqdm.auto import tqdm\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0c4705c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:57:08.932774Z",
     "iopub.status.busy": "2023-03-26T13:57:08.931003Z",
     "iopub.status.idle": "2023-03-26T13:57:08.998618Z",
     "shell.execute_reply": "2023-03-26T13:57:08.997643Z"
    },
    "papermill": {
     "duration": 0.076735,
     "end_time": "2023-03-26T13:57:09.000940",
     "exception": false,
     "start_time": "2023-03-26T13:57:08.924205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "myseed = 6666  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76281fb1",
   "metadata": {
    "papermill": {
     "duration": 0.005515,
     "end_time": "2023-03-26T13:57:09.012171",
     "exception": false,
     "start_time": "2023-03-26T13:57:09.006656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e5cdebc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:57:09.025302Z",
     "iopub.status.busy": "2023-03-26T13:57:09.024384Z",
     "iopub.status.idle": "2023-03-26T13:57:09.032154Z",
     "shell.execute_reply": "2023-03-26T13:57:09.031260Z"
    },
    "papermill": {
     "duration": 0.016523,
     "end_time": "2023-03-26T13:57:09.034249",
     "exception": false,
     "start_time": "2023-03-26T13:57:09.017726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normally, We don't need augmentations in testing and validation.\n",
    "# All we need here is to resize the PIL image and transform it into Tensor.\n",
    "test_tfm = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# However, it is also possible to use augmentation in the testing phase.\n",
    "# You may use train_tfm to produce a variety of images and then test using ensemble methods\n",
    "train_tfm = transforms.Compose([\n",
    "    # Resize the image into a fixed shape (height = width = 128)\n",
    "    transforms.Resize((128, 128)),\n",
    "    # You may add some transforms here.\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomResizedCrop((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomAffine(30),\n",
    "    transforms.RandomGrayscale(0.2),\n",
    "    transforms.ColorJitter(brightness = 0.4, saturation = 0.4, contrast = 0.4),\n",
    "#     ImageNetPolicy(),\n",
    "    \n",
    "#     # ToTensor() should be the last one of the transforms.\n",
    "    transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549f5a89",
   "metadata": {
    "papermill": {
     "duration": 0.005345,
     "end_time": "2023-03-26T13:57:09.045064",
     "exception": false,
     "start_time": "2023-03-26T13:57:09.039719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2192bc9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:57:09.057701Z",
     "iopub.status.busy": "2023-03-26T13:57:09.057149Z",
     "iopub.status.idle": "2023-03-26T13:57:09.066329Z",
     "shell.execute_reply": "2023-03-26T13:57:09.065454Z"
    },
    "papermill": {
     "duration": 0.017748,
     "end_time": "2023-03-26T13:57:09.068388",
     "exception": false,
     "start_time": "2023-03-26T13:57:09.050640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FoodDataset(Dataset):\n",
    "\n",
    "    def __init__(self,path,tfm=test_tfm,files = None):\n",
    "        super(FoodDataset).__init__()\n",
    "        self.path = path\n",
    "        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n",
    "        if files != None:\n",
    "            self.files = files\n",
    "            \n",
    "        self.transform = tfm\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "  \n",
    "    def __getitem__(self,idx):\n",
    "        fname = self.files[idx]\n",
    "        im = Image.open(fname)\n",
    "        im = self.transform(im)\n",
    "        \n",
    "        try:\n",
    "            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n",
    "        except:\n",
    "            label = -1 # test has no label\n",
    "            \n",
    "        return im,label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ee881f",
   "metadata": {
    "papermill": {
     "duration": 0.005389,
     "end_time": "2023-03-26T13:57:09.079470",
     "exception": false,
     "start_time": "2023-03-26T13:57:09.074081",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3fac2ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:57:09.092159Z",
     "iopub.status.busy": "2023-03-26T13:57:09.091893Z",
     "iopub.status.idle": "2023-03-26T13:57:09.431911Z",
     "shell.execute_reply": "2023-03-26T13:57:09.430847Z"
    },
    "papermill": {
     "duration": 0.3497,
     "end_time": "2023-03-26T13:57:09.434843",
     "exception": false,
     "start_time": "2023-03-26T13:57:09.085143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "        # SE layers\n",
    "        self.fc1 = nn.Conv2d(planes, planes//16, kernel_size=1)\n",
    "        self.fc2 = nn.Conv2d(planes//16, planes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "\n",
    "        # Squeeze\n",
    "        w = F.avg_pool2d(out, out.size(2))\n",
    "        w = F.relu(self.fc1(w))\n",
    "        w = F.sigmoid(self.fc2(w))\n",
    "        # Excitation\n",
    "        out = out * w\n",
    "\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "\n",
    "class SENet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(SENet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block,  64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def SENet18():\n",
    "    return SENet(PreActBlock, [2,2,2,2])\n",
    "\n",
    "\n",
    "net = SENet18()\n",
    "y = net(torch.randn(1,3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6197785",
   "metadata": {
    "papermill": {
     "duration": 0.006187,
     "end_time": "2023-03-26T13:57:09.447130",
     "exception": false,
     "start_time": "2023-03-26T13:57:09.440943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bc8cca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:57:09.459892Z",
     "iopub.status.busy": "2023-03-26T13:57:09.459589Z",
     "iopub.status.idle": "2023-03-26T13:57:09.470576Z",
     "shell.execute_reply": "2023-03-26T13:57:09.469634Z"
    },
    "papermill": {
     "duration": 0.019979,
     "end_time": "2023-03-26T13:57:09.472852",
     "exception": false,
     "start_time": "2023-03-26T13:57:09.452873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [0.5,1,0.25,1,0.125,0.25,0.5,1,0.5,0.5,0.5]\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# [0.5,0.125,0.75,0.125,0.9,0.75,0.5,0.125,0.5,0.5,0.5]\n",
    "class FocalLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=1.2, alpha=[0.25, 0.25, 0.45, 0.25, 0.45, 0.45, 0.25, 0.25, 0.25, 0.25, 0.25], size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha, (float, int)): self.alpha = torch.Tensor([alpha, 1 - alpha])\n",
    "        if isinstance(alpha, list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0), input.size(1), -1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1, 2)                         # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1, input.size(2))    # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1, 1)\n",
    "\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = logpt.exp()\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type() != input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0, target.data.view(-1))\n",
    "            logpt = logpt * at\n",
    "\n",
    "        loss = -1 * (1 - pt)**self.gamma * logpt\n",
    "        if self.size_average: return loss.mean()\n",
    "        else: return loss.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bbfbb48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:57:09.486860Z",
     "iopub.status.busy": "2023-03-26T13:57:09.485964Z",
     "iopub.status.idle": "2023-03-26T13:57:12.635006Z",
     "shell.execute_reply": "2023-03-26T13:57:12.633893Z"
    },
    "papermill": {
     "duration": 3.15867,
     "end_time": "2023-03-26T13:57:12.637551",
     "exception": false,
     "start_time": "2023-03-26T13:57:09.478881",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"cuda\" only when GPUs are available.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize a model, and put it on the device specified.\n",
    "# model = SENet18()\n",
    "model = models.resnet50(weights = None)\n",
    "# model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=False)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'densenet161', weights=None)\n",
    "# model= nn.DataParallel(model)\n",
    "model.to(device)\n",
    "ensemble_num = 3\n",
    "# models = [models.resnet18(weights = None).to(device) for i in range(ensemble_num)]\n",
    "# optimizers = [torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4) for model in models]\n",
    "# The number of batch size.\n",
    "batch_size = 64\n",
    "\n",
    "# The number of training epochs.\n",
    "n_epochs = 300\n",
    "\n",
    "# If no improvement in 'patience' epochs, early stop.\n",
    "patience = 40\n",
    "\n",
    "# For the classification task, we use cross-entropy as the measurement of performance.\n",
    "# criterion = nn.CrossEntropyLoss(label_smoothing = 0.08)\n",
    "criterion = FocalLoss()\n",
    "\n",
    "# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = 40,T_mult = 2)\n",
    "# scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max = 10)\n",
    "# schedulers = [lr_scheduler.CosineAnnealingLR(optimizer, T_max = 10) for model in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce2f17",
   "metadata": {
    "papermill": {
     "duration": 0.005596,
     "end_time": "2023-03-26T13:57:12.649275",
     "exception": false,
     "start_time": "2023-03-26T13:57:12.643679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bc27bef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:57:12.662093Z",
     "iopub.status.busy": "2023-03-26T13:57:12.661502Z",
     "iopub.status.idle": "2023-03-26T13:57:12.886298Z",
     "shell.execute_reply": "2023-03-26T13:57:12.885346Z"
    },
    "papermill": {
     "duration": 0.233847,
     "end_time": "2023-03-26T13:57:12.888683",
     "exception": false,
     "start_time": "2023-03-26T13:57:12.654836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct train and valid datasets.\n",
    "# The argument \"loader\" tells how torchvision reads the data.\n",
    "train_set = FoodDataset(\"/kaggle/input/ml2023spring-hw3/train\", tfm=train_tfm)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_set = FoodDataset(\"/kaggle/input/ml2023spring-hw3/valid\", tfm=test_tfm)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9405565",
   "metadata": {
    "papermill": {
     "duration": 0.005439,
     "end_time": "2023-03-26T13:57:12.900148",
     "exception": false,
     "start_time": "2023-03-26T13:57:12.894709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75ec0b66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:57:12.912849Z",
     "iopub.status.busy": "2023-03-26T13:57:12.912549Z",
     "iopub.status.idle": "2023-03-26T13:57:12.918024Z",
     "shell.execute_reply": "2023-03-26T13:57:12.917051Z"
    },
    "papermill": {
     "duration": 0.014503,
     "end_time": "2023-03-26T13:57:12.920293",
     "exception": false,
     "start_time": "2023-03-26T13:57:12.905790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def trainer_k_folds(config, dataset_dir, batch_size, train_tfm, test_tfm, devices):\n",
    "#     train_dir = os.path.join(dataset_dir,\"training\")\n",
    "#     val_dir = os.path.join(dataset_dir,\"validation\")\n",
    "#     train_files = [os.path.join(train_dir, x) for x in os.listdir(train_dir) if x.endswith('.jpg')]\n",
    "#     val_files = [os.path.join(val_dir, x) for x in os.listdir(val_dir) if x.endswith('.jpg')]\n",
    "#     total_files = np.array(train_files + val_files)\n",
    "#     random.shuffle(total_files)\n",
    "#     num_folds = config['num_folds']   \n",
    "#     train_folds = np.array_split(np.arange(len(total_files)), num_folds)\n",
    "#     train_folds = np.array(train_folds, dtype=object) # 防止因为数组维度不整齐而报错\n",
    "        \n",
    "#     for i in range(num_folds):\n",
    "#         print(f'\\n\\nStarting Fold: {i} ********************************************')  \n",
    "#         train_data = total_files[np.concatenate(np.delete(train_folds, i)) ] \n",
    "#         val_data = total_files[train_folds[i]]        \n",
    "    \n",
    "#         train_set = FoodDataset(tfm=train_tfm, files=train_data)\n",
    "#         train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last = True)    \n",
    "#         valid_set = FoodDataset(tfm=test_tfm, files=val_data)\n",
    "#         valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last = True)\n",
    "#         print('训练集总长度是 {:d}, batch数量是 {:.2f}'.format(len(train_set), len(train_set)/ batch_size))\n",
    "#         print('验证集总长度是 {:d}, batch数量是 {:.2f}'.format(len(valid_set), len(valid_set)/ batch_size))\n",
    "        \n",
    "# #         tep = config['model_path']\n",
    "# #         config['model_path'] += f\"Fold_{i}_best\"\n",
    "# #         config['best_acc'] = 0.0\n",
    "#         model = models.resnet18().to(device)\n",
    "#         # model.load_state_dict(torch.load('models/foldmodel0.0001')) 提前训练几个epoch，可能加快后面每一个模型的训练\n",
    "#         trainer(train_loader, valid_loader, model, config, devices)\n",
    "#         config['best_accs'].append(config['best_acc'])\n",
    "#         config['model_path'] = tep\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d98767d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T13:57:12.933554Z",
     "iopub.status.busy": "2023-03-26T13:57:12.932838Z",
     "iopub.status.idle": "2023-03-26T22:56:50.890600Z",
     "shell.execute_reply": "2023-03-26T22:56:50.887378Z"
    },
    "papermill": {
     "duration": 32377.966932,
     "end_time": "2023-03-26T22:56:50.892884",
     "exception": false,
     "start_time": "2023-03-26T13:57:12.925952",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize trackers, these are not parameters and should not be changed\n",
    "stale = 0\n",
    "best_acc = 0\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # ---------- Training ----------\n",
    "    # Make sure the model is in train mode before training.\n",
    "    model.train()\n",
    "\n",
    "    # These are used to record information in training.\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "    index = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "\n",
    "        # A batch consists of image data and corresponding labels.\n",
    "        imgs, labels = batch\n",
    "        #imgs = imgs.half()\n",
    "        #print(imgs.shape,labels.shape)\n",
    "\n",
    "        # Forward the data. (Make sure data and model are on the same device.)\n",
    "        logits = model(imgs.to(device))\n",
    "\n",
    "        # Calculate the cross-entropy loss.\n",
    "        # We don't need to apply softmax before computing cross-entropy as it is done automatically.\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "\n",
    "        # Gradients stored in the parameters in the previous step should be cleared out first.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Compute the gradients for parameters.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the gradient norms for stable training.\n",
    "        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "\n",
    "        # Update the parameters with computed gradients.\n",
    "#         scheduler.step(epoch+index/len(train_loader))\n",
    "        optimizer.step()\n",
    "        index+=1\n",
    "#         scheduler.step()\n",
    "        # Compute the accuracy for current batch.\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        # Record the loss and accuracy.\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "        \n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "\n",
    "    # Print the information.\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
    "    model.eval()\n",
    "\n",
    "    # These are used to record information in validation.\n",
    "    valid_loss = []\n",
    "    valid_accs = []\n",
    "\n",
    "    # Iterate the validation set by batches.\n",
    "    for batch in tqdm(valid_loader):\n",
    "\n",
    "        # A batch consists of image data and corresponding labels.\n",
    "        imgs, labels = batch\n",
    "        #imgs = imgs.half()\n",
    "\n",
    "        # We don't need gradient in validation.\n",
    "        # Using torch.no_grad() accelerates the forward process.\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "\n",
    "        # We can still compute the loss (but not the gradient).\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "\n",
    "        # Compute the accuracy for current batch.\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "\n",
    "        # Record the loss and accuracy.\n",
    "        valid_loss.append(loss.item())\n",
    "        valid_accs.append(acc)\n",
    "        #break\n",
    "\n",
    "    # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "\n",
    "    # Print the information.\n",
    "    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "\n",
    "\n",
    "    # update logs\n",
    "    if valid_acc > best_acc:\n",
    "        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n",
    "            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n",
    "    else:\n",
    "        with open(f\"./{_exp_name}_log.txt\",\"a\"):\n",
    "            print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n",
    "\n",
    "\n",
    "    # save models\n",
    "    if valid_acc > best_acc:\n",
    "        print(f\"Best model found at epoch {epoch}, saving model\")\n",
    "        torch.save(model.state_dict(), f\"{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n",
    "        best_acc = valid_acc\n",
    "        stale = 0\n",
    "    else:\n",
    "        stale += 1\n",
    "        if stale > patience:\n",
    "            print(f\"No improvment {patience} consecutive epochs, early stopping\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c5856",
   "metadata": {
    "papermill": {
     "duration": 3.624515,
     "end_time": "2023-03-26T22:56:57.758951",
     "exception": false,
     "start_time": "2023-03-26T22:56:54.134436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataloader for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8101f501",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T22:57:04.049990Z",
     "iopub.status.busy": "2023-03-26T22:57:04.049605Z",
     "iopub.status.idle": "2023-03-26T22:57:04.175144Z",
     "shell.execute_reply": "2023-03-26T22:57:04.174172Z"
    },
    "papermill": {
     "duration": 3.325169,
     "end_time": "2023-03-26T22:57:04.177311",
     "exception": false,
     "start_time": "2023-03-26T22:57:00.852142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Construct test datasets.\n",
    "# The argument \"loader\" tells how torchvision reads the data.\n",
    "test_set = FoodDataset(\"/kaggle/input/ml2023spring-hw3/test\", tfm=test_tfm)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loaders = []\n",
    "for i in range(5):\n",
    "    test_set_i = FoodDataset(\"/kaggle/input/ml2023spring-hw3/test\", tfm=train_tfm)\n",
    "    test_loader_i = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    test_loaders.append(test_loader_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97eadc3",
   "metadata": {
    "papermill": {
     "duration": 3.275771,
     "end_time": "2023-03-26T22:57:10.854452",
     "exception": false,
     "start_time": "2023-03-26T22:57:07.578681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Testing and generate prediction CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1f89eb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T22:57:17.263995Z",
     "iopub.status.busy": "2023-03-26T22:57:17.263619Z",
     "iopub.status.idle": "2023-03-26T22:59:13.195198Z",
     "shell.execute_reply": "2023-03-26T22:59:13.193897Z"
    },
    "papermill": {
     "duration": 119.142702,
     "end_time": "2023-03-26T22:59:13.198162",
     "exception": false,
     "start_time": "2023-03-26T22:57:14.055460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:22<00:00,  2.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# model_best =SENet18()\n",
    "# import torchvision.models as models\n",
    "model_best = models.resnet50(weights = None)\n",
    "# model_best = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=False)\n",
    "# model_best = torch.hub.load('pytorch/vision:v0.10.0', 'densenet161', weights = None)\n",
    "\n",
    "# model_best = nn.DataParallel(model_best)\n",
    "model_best.to(device)\n",
    "\n",
    "model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\n",
    "# model_best.load_state_dict(torch.load(\"/kaggle/input\"))\n",
    "\n",
    "model_best.eval()\n",
    "preds = [[],[],[],[],[],[]]\n",
    "prediction = []\n",
    "with torch.no_grad():\n",
    "    for data,_ in tqdm(test_loader):\n",
    "        test_pred = model_best(data.to(device)).cpu().data.numpy()\n",
    "        preds[0].extend(test_pred)\n",
    "#         test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
    "#         prediction += test_label.squeeze().tolist()\n",
    "    \n",
    "    for i,loader in enumerate(test_loaders):\n",
    "        for data,_ in (loader):\n",
    "            test_pred = model_best(data.to(device)).cpu().data.numpy()\n",
    "            preds[i+1].extend(test_pred)\n",
    "            \n",
    "    #         test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n",
    "    #         prediction += test_label.squeeze().tolist()\n",
    "\n",
    "pred_np = np.array(preds, dtype = object)\n",
    "tmp = 0.6*pred_np[0]\n",
    "for i in range(1, 6):\n",
    "    tmp+=0.1*pred_np[i]\n",
    "\n",
    "prediction = np.argmax(tmp, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edc49624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T22:59:19.697266Z",
     "iopub.status.busy": "2023-03-26T22:59:19.696882Z",
     "iopub.status.idle": "2023-03-26T22:59:19.727517Z",
     "shell.execute_reply": "2023-03-26T22:59:19.726574Z"
    },
    "papermill": {
     "duration": 3.174794,
     "end_time": "2023-03-26T22:59:19.729871",
     "exception": false,
     "start_time": "2023-03-26T22:59:16.555077",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create test csv\n",
    "def pad4(i):\n",
    "    return \"0\"*(4-len(str(i)))+str(i)\n",
    "df = pd.DataFrame()\n",
    "df[\"Id\"] = [pad4(i) for i in range(len(test_set))]\n",
    "df[\"Category\"] = prediction\n",
    "df.to_csv(\"submission.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7eb90a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T22:59:26.964117Z",
     "iopub.status.busy": "2023-03-26T22:59:26.963487Z",
     "iopub.status.idle": "2023-03-26T22:59:26.968879Z",
     "shell.execute_reply": "2023-03-26T22:59:26.967811Z"
    },
    "papermill": {
     "duration": 3.793398,
     "end_time": "2023-03-26T22:59:26.971101",
     "exception": false,
     "start_time": "2023-03-26T22:59:23.177703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# # Make sure the model is in eval mode.\n",
    "# # Some modules like Dropout or BatchNorm affect if the model is in training mode.\n",
    "\n",
    "\n",
    "\n",
    "# # Initialize a list to store the predictions.\n",
    "# predictions = []\n",
    "\n",
    "# # Iterate the testing set by batches.\n",
    "# for batch in tqdm(test_loader):\n",
    "#     # A batch consists of image data and corresponding labels.\n",
    "#     # But here the variable \"labels\" is useless since we do not have the ground-truth.\n",
    "#     # If printing out the labels, you will find that it is always 0.\n",
    "#     # This is because the wrapper (DatasetFolder) returns images and labels for each batch,\n",
    "#     # so we have to create fake labels to make it work normally.\n",
    "#     imgs, labels = batch\n",
    "\n",
    "# #     # We don't need gradient in testing, and we don't even have labels to compute loss.\n",
    "# #     # Using torch.no_grad() accelerates the forward process.\n",
    "#     with torch.no_grad():\n",
    "#         logits1 = model1(imgs.to(device))\n",
    "#         logits2 = model2(imgs.to(device))\n",
    "#         logits3 = model3(imgs.to(device))\n",
    "#         logits = (logits1 + logits2 + logits3) / 3\n",
    "\n",
    "# #     # Take the class with greatest logit as prediction and record it.\n",
    "#     predictions.extend(logits.argmax(dim=-1).cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55de1ba0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T22:59:33.468594Z",
     "iopub.status.busy": "2023-03-26T22:59:33.468210Z",
     "iopub.status.idle": "2023-03-26T22:59:33.473452Z",
     "shell.execute_reply": "2023-03-26T22:59:33.472331Z"
    },
    "papermill": {
     "duration": 3.398144,
     "end_time": "2023-03-26T22:59:33.475659",
     "exception": false,
     "start_time": "2023-03-26T22:59:30.077515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # batch_size = 256\n",
    "\n",
    " \n",
    "# preds = [[], [], [], [], [], []] \n",
    "\n",
    "# model1 = models.resnet18().to(device)\n",
    "# model1.load_state_dict(torch.load('/kaggle/input/model-d/sample_best772.ckpt'))\n",
    "# model2 = models.resnet18().to(device)\n",
    "# model2.load_state_dict(torch.load('/kaggle/input/model-b/sample_best-78.ckpt'))\n",
    "# model3 = models.resnet18().to(device)\n",
    "# model3.load_state_dict(torch.load('/kaggle/input/model-c/sample_best782.ckpt'))\n",
    "# models_ = [model1, model2, model3]\n",
    "# with torch.no_grad():\n",
    "#     for data, _ in test_loader:\n",
    "#         batch_preds = [] \n",
    "#         for model_best in models_:\n",
    "#             batch_preds.append(model_best(data.to(device)).cpu().data.numpy())\n",
    "#         batch_preds = sum(batch_preds)\n",
    "#         preds[0].extend(batch_preds.squeeze().tolist())    \n",
    "    \n",
    "#     for i, loader in enumerate(test_loaders):\n",
    "#         for data, _ in loader:\n",
    "#             batch_preds = []\n",
    "#             for model_best in models_:\n",
    "#                 batch_preds.append(model_best(data.to(device)).cpu().data.numpy())\n",
    "#             batch_preds = sum(batch_preds)\n",
    "#             preds[i+1].extend(batch_preds.squeeze().tolist())\n",
    "# pred_np = np.array(preds, dtype = object)\n",
    "# tmp = 0.6*pred_np[0]\n",
    "# for i in range(1, 6):\n",
    "#     tmp+=0.1*pred_np[i]\n",
    "\n",
    "# prediction = np.argmax(tmp, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379c65d4",
   "metadata": {
    "papermill": {
     "duration": 3.363534,
     "end_time": "2023-03-26T22:59:40.044930",
     "exception": false,
     "start_time": "2023-03-26T22:59:36.681396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2186ec2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T22:59:46.710085Z",
     "iopub.status.busy": "2023-03-26T22:59:46.709718Z",
     "iopub.status.idle": "2023-03-26T22:59:46.714848Z",
     "shell.execute_reply": "2023-03-26T22:59:46.713144Z"
    },
    "papermill": {
     "duration": 3.35027,
     "end_time": "2023-03-26T22:59:46.717034",
     "exception": false,
     "start_time": "2023-03-26T22:59:43.366764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Save predictions into the file.\n",
    "# with open(\"Ensemble2.csv\", \"w\") as f:\n",
    "\n",
    "#     # The first row must be \"Id, Category\"\n",
    "#     f.write(\"Id,Category\\n\")\n",
    "\n",
    "#     # For the rest of the rows, each image id corresponds to a predicted class.\n",
    "#     for i, pred in  enumerate(prediction):\n",
    "#          f.write(f\"{i},{pred}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32576.143293,
   "end_time": "2023-03-26T22:59:51.802636",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-26T13:56:55.659343",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
