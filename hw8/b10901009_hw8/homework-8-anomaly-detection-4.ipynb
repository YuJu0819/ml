{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Homework 8 - Anomaly Detection**\n\nIf there are any questions, please contact mlta-2023-spring@googlegroups.com\n\nSlide:    [Link](https://docs.google.com/presentation/d/18LkR8qulwSbi3SVoLl1XNNGjQQ_qczs_35lrJWOmHCk/edit?usp=sharing)　Kaggle: [Link](https://www.kaggle.com/t/c76950cc460140eba30a576ca7668d28)","metadata":{"id":"YiVfKn-6tXz8"}},{"cell_type":"markdown","source":"# Set up the environment\n","metadata":{"id":"bDk9r2YOcDc9"}},{"cell_type":"markdown","source":"## Package installation","metadata":{"id":"Oi12tJMYWi0Q"}},{"cell_type":"code","source":"# Training progress bar\n!pip install -q qqdm","metadata":{"id":"7LexxyPWWjJB","outputId":"2039780b-43f2-49b5-ffa8-2a0c33ad2d15","execution":{"iopub.status.busy":"2023-05-19T06:55:39.296822Z","iopub.execute_input":"2023-05-19T06:55:39.297299Z","iopub.status.idle":"2023-05-19T06:55:52.636029Z","shell.execute_reply.started":"2023-05-19T06:55:39.297262Z","shell.execute_reply":"2023-05-19T06:55:52.634547Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## Downloading data","metadata":{"id":"DCgNXSsEWuY7"}},{"cell_type":"code","source":"!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh |  bash\n!apt-get install -y --allow-unauthenticated git-lfs","metadata":{"execution":{"iopub.status.busy":"2023-05-19T06:55:57.597890Z","iopub.execute_input":"2023-05-19T06:55:57.599114Z","iopub.status.idle":"2023-05-19T06:56:10.787020Z","shell.execute_reply.started":"2023-05-19T06:55:57.599053Z","shell.execute_reply":"2023-05-19T06:56:10.785720Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Detected operating system as Ubuntu/focal.\nChecking for curl...\nDetected curl...\nChecking for gpg...\nDetected gpg...\nDetected apt version as 2.0.9\nRunning apt-get update... done.\nInstalling apt-transport-https... done.\nInstalling /etc/apt/sources.list.d/github_git-lfs.list...done.\nImporting packagecloud gpg key... Packagecloud gpg key imported to /etc/apt/keyrings/github_git-lfs-archive-keyring.gpg\ndone.\nRunning apt-get update... done.\n\nThe repository is setup! You can now install packages.\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\ngit-lfs is already the newest version (3.3.0).\n0 upgraded, 0 newly installed, 0 to remove and 88 not upgraded.\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/chiyuanhsiao/ml2023spring-hw8","metadata":{"execution":{"iopub.status.busy":"2023-05-19T06:56:14.956102Z","iopub.execute_input":"2023-05-19T06:56:14.956588Z","iopub.status.idle":"2023-05-19T06:57:02.400056Z","shell.execute_reply.started":"2023-05-19T06:56:14.956546Z","shell.execute_reply":"2023-05-19T06:57:02.398255Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Cloning into 'ml2023spring-hw8'...\nremote: Enumerating objects: 11, done.\u001b[K\nremote: Counting objects: 100% (11/11), done.\u001b[K\nremote: Compressing objects: 100% (10/10), done.\u001b[K\nremote: Total 11 (delta 2), reused 8 (delta 0), pack-reused 0\u001b[K\nReceiving objects: 100% (11/11), done.\nResolving deltas: 100% (2/2), done.\nFiltering content: 100% (2/2), 1.36 GiB | 30.79 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working/ml2023spring-hw8\n!git lfs install\n!git lfs pull","metadata":{"id":"e-yCMrIl4L60","outputId":"7a5c329a-933e-4564-8423-b11469700577","execution":{"iopub.status.busy":"2023-05-19T06:57:02.403014Z","iopub.execute_input":"2023-05-19T06:57:02.403495Z","iopub.status.idle":"2023-05-19T06:57:04.859861Z","shell.execute_reply.started":"2023-05-19T06:57:02.403429Z","shell.execute_reply":"2023-05-19T06:57:04.858359Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"/kaggle/working/ml2023spring-hw8\nUpdated Git hooks.\nGit LFS initialized.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import packages","metadata":{"id":"HNe7QU7n7cqh"}},{"cell_type":"code","source":"import random\nimport numpy as np\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torchvision.models as models\nfrom torch.optim import Adam, AdamW\nfrom qqdm import qqdm, format_str\nimport pandas as pd","metadata":{"id":"Jk3qFK_a7k8P","execution":{"iopub.status.busy":"2023-05-19T06:57:06.853212Z","iopub.execute_input":"2023-05-19T06:57:06.853648Z","iopub.status.idle":"2023-05-19T06:57:06.863035Z","shell.execute_reply.started":"2023-05-19T06:57:06.853606Z","shell.execute_reply":"2023-05-19T06:57:06.861023Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Loading data","metadata":{"id":"6X6fkGPnYyaF"}},{"cell_type":"code","source":"train = np.load('/kaggle/working/ml2023spring-hw8/trainingset.npy', allow_pickle=True)[:,8:56,8:56,:]\ntest = np.load('/kaggle/working/ml2023spring-hw8/testingset.npy', allow_pickle=True)[:,8:56,8:56,:]\n\nprint(train.shape)\nprint(test.shape)","metadata":{"id":"k7Wd4yiUYzAm","outputId":"d8b80f1e-cbc4-4ed9-c95c-b2e3fb561f23","execution":{"iopub.status.busy":"2023-05-19T06:57:09.895423Z","iopub.execute_input":"2023-05-19T06:57:09.895837Z","iopub.status.idle":"2023-05-19T06:57:30.989605Z","shell.execute_reply.started":"2023-05-19T06:57:09.895802Z","shell.execute_reply":"2023-05-19T06:57:30.988345Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"(100000, 48, 48, 3)\n(19636, 48, 48, 3)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Random seed\nSet the random seed to a certain value for reproducibility.","metadata":{"id":"_flpmj6OYIa6"}},{"cell_type":"code","source":"def same_seeds(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\nsame_seeds(44)","metadata":{"id":"Gb-dgXQYYI2Q","execution":{"iopub.status.busy":"2023-05-19T06:57:30.991793Z","iopub.execute_input":"2023-05-19T06:57:30.992864Z","iopub.status.idle":"2023-05-19T06:57:31.000692Z","shell.execute_reply.started":"2023-05-19T06:57:30.992810Z","shell.execute_reply":"2023-05-19T06:57:30.999523Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":"# Autoencoder","metadata":{"id":"zR9zC0_Df-CR"}},{"cell_type":"markdown","source":"# Models & loss","metadata":{"id":"1EbfwRREhA7c"}},{"cell_type":"code","source":"class fcn_autoencoder(nn.Module):\n    def __init__(self):\n        super(fcn_autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(48 * 48 * 3, 512),\n            nn.ReLU(),\n            nn.Linear(512, 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, 128),\n            nn.ReLU(),\n            nn.Linear(128, 64),\n            nn.ReLU(),  \n            nn.Linear(64, 32),\n            nn.ReLU(),\n            nn.Linear(32, 16),\n            nn.ReLU(),\n            nn.Linear(16, 10)\n        \n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(10, 16),\n            nn.ReLU(),\n            nn.Linear(16, 32),\n            nn.ReLU(),\n            nn.Linear(32, 64),\n            nn.ReLU(),\n            nn.Linear(64, 128),\n            nn.ReLU(),\n            nn.Linear(128, 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, 512),\n            nn.ReLU(),\n            nn.Linear(512, 48 * 48 * 3),\n            nn.Tanh()\n        )\n \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n\n# maybe it can be smaller\nclass conv_autoencoder(nn.Module):\n    def __init__(self):\n        super(conv_autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 12, 4, stride=2, padding=1),         \n            nn.ReLU(),\n            nn.Conv2d(12, 24, 4, stride=2, padding=1),        \n            nn.ReLU(),\n\t\t\tnn.Conv2d(24, 48, 4, stride=2, padding=1),         \n            nn.ReLU(),\n            nn.Flatten(1,3),\n            nn.Linear(48*6*6, 48),\n            nn.ReLU(),\n        )\n#         self.fce = nn.Sequential(\n            \n#         )\n#         self.fcd = nn.Sequential(\n            \n#         )\n        self.decoder = nn.Sequential(\n            nn.Linear(48, 48*6*6),\n            nn.ReLU(),\n            nn.Unflatten(1, (48,6,6)),\n\t\t\tnn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),\n            nn.ReLU(),\n\t\t\tnn.ConvTranspose2d(24, 12, 4, stride=2, padding=1), \n            nn.ReLU(),\n            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),\n            nn.Tanh(),\n        )\n\n    def forward(self, x):\n        x = self.encoder(x)\n#         x = self.fce(x)\n#         x = self.fcd(x)\n        x = self.decoder(x)\n        return x\n\n\n\n\nclass VAE(nn.Module):\n    def __init__(self):\n        super(VAE, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 12, 4, stride=2, padding=1),            \n            nn.ReLU(),\n            nn.Conv2d(12, 24, 4, stride=2, padding=1),    \n            nn.ReLU(),\n        )\n        self.enc_out_1 = nn.Sequential(\n            nn.Conv2d(24, 48, 4, stride=2, padding=1),  \n            nn.ReLU(),\n        )\n        self.enc_out_2 = nn.Sequential(\n            nn.Conv2d(24, 48, 4, stride=2, padding=1),\n            nn.ReLU(),\n        )\n        self.decoder = nn.Sequential(\n\t\t\t      nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1), \n            nn.ReLU(),\n\t\t\t      nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1), \n            nn.ReLU(),\n            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1), \n            nn.Tanh(),\n        )\n\n    def encode(self, x):\n        h1 = self.encoder(x)\n        return self.enc_out_1(h1), self.enc_out_2(h1)\n\n    def reparametrize(self, mu, logvar):\n        std = logvar.mul(0.5).exp_()\n        if torch.cuda.is_available():\n            eps = torch.cuda.FloatTensor(std.size()).normal_()\n        else:\n            eps = torch.FloatTensor(std.size()).normal_()\n        eps = Variable(eps)\n        return eps.mul(std).add_(mu)\n\n    def decode(self, z):\n        return self.decoder(z)\n\n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparametrize(mu, logvar)\n        return self.decode(z), mu, logvar\n\n\ndef loss_vae(recon_x, x, mu, logvar, criterion):\n    \"\"\"\n    recon_x: generating images\n    x: origin images\n    mu: latent mean\n    logvar: latent log variance\n    \"\"\"\n    mse = criterion(recon_x, x)  # mse loss\n    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n    KLD = torch.sum(KLD_element).mul_(-0.5)\n    return mse + KLD","metadata":{"id":"Wi8ds1fugCkR","execution":{"iopub.status.busy":"2023-05-19T06:57:31.002796Z","iopub.execute_input":"2023-05-19T06:57:31.003208Z","iopub.status.idle":"2023-05-19T06:57:31.040293Z","shell.execute_reply.started":"2023-05-19T06:57:31.003170Z","shell.execute_reply":"2023-05-19T06:57:31.039147Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Dataset module\n\nModule for obtaining and processing data. The transform function here normalizes image's pixels from [0, 255] to [-1.0, 1.0].\n","metadata":{"id":"vrJ9bScg9AgO"}},{"cell_type":"code","source":"class CustomTensorDataset(TensorDataset):\n    \"\"\"TensorDataset with support of transforms.\n    \"\"\"\n    def __init__(self, tensors):\n        self.tensors = tensors\n        if tensors.shape[-1] == 3:\n            self.tensors = tensors.permute(0, 3, 1, 2)\n        \n        self.transform = transforms.Compose([\n          transforms.Lambda(lambda x: x.to(torch.float32)),\n          transforms.Lambda(lambda x: 2. * x/255. - 1.),\n        ])\n        \n    def __getitem__(self, index):\n        x = self.tensors[index]\n        \n        if self.transform:\n            # mapping images to [-1.0, 1.0]\n            x = self.transform(x)\n\n        return x\n\n    def __len__(self):\n        return len(self.tensors)","metadata":{"id":"33fWhE-h9LPq","execution":{"iopub.status.busy":"2023-05-19T06:57:34.368119Z","iopub.execute_input":"2023-05-19T06:57:34.368973Z","iopub.status.idle":"2023-05-19T06:57:34.378699Z","shell.execute_reply.started":"2023-05-19T06:57:34.368923Z","shell.execute_reply":"2023-05-19T06:57:34.377536Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"XKNUImqUhIeq"}},{"cell_type":"markdown","source":"## Configuration\n","metadata":{"id":"7ebAJdjFmS08"}},{"cell_type":"code","source":"class Residual_Block(nn.Module):\n    def __init__(self, ic, oc, stride=1):\n        super().__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(ic, oc, kernel_size=3, stride=stride, padding=1),\n            nn.BatchNorm2d(oc),\n            nn.ReLU(inplace=True)\n        )\n        \n        self.conv2 = nn.Sequential(\n            nn.Conv2d(oc, oc, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(oc),\n        )\n        \n        self.relu = nn.ReLU(inplace=True)\n    \n        self.downsample = None\n        if stride != 1 or (ic != oc):\n            self.downsample = nn.Sequential(\n                nn.Conv2d(ic, oc, kernel_size=1, stride=stride),\n                nn.BatchNorm2d(oc),\n            )\n        \n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.conv2(out)\n        \n        if self.downsample:\n            residual = self.downsample(x)\n            \n        out += residual\n        return self.relu(out)\n    \nclass ResNet(nn.Module):\n    def __init__(self, block=Residual_Block, num_layers=[2, 1, 1, 1]):\n        super().__init__()\n        self.preconv = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n        )\n        self.layer0 = self.make_residual(block, 32, 64,  num_layers[0], stride=2)\n        self.layer1 = self.make_residual(block, 64, 128, num_layers[1], stride=2)\n        self.layer2 = self.make_residual(block, 128, 128, num_layers[2], stride=2)\n        self.layer3 = self.make_residual(block, 128, 64, num_layers[3], stride=2)\n        \n        self.fc = nn.Sequential(\n            nn.Flatten(),\n            nn.Dropout(0.2),\n            nn.Linear(36*4*4, 64),\n            nn.BatchNorm1d(64),\n            nn.ReLU(inplace=True),\n        )\n        \n        self.decoder = nn.Sequential(\n            nn.Linear(64, 64*4*4),\n            nn.BatchNorm1d(64*4*4),\n            nn.ReLU(),\n            nn.Unflatten(1, (64, 4, 4)),\n            nn.ConvTranspose2d(64, 128, 4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, 128, 4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, 128, 4, stride=2, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.ConvTranspose2d(128, 3, 4, stride=2, padding=1),\n            nn.Tanh(),\n        )\n    def make_residual(self, block, ic, oc, num_layer, stride=1):\n        layers = []\n        layers.append(block(ic, oc, stride))\n        for i in range(1, num_layer):\n            layers.append(block(oc, oc))\n        return nn.Sequential(*layers)\n    \n    def encoder(self, x):\n        x = self.preconv(x)\n        x = self.layer0(x) #64*64 --> 32*32\n        x = self.layer1(x) #32*32 --> 16*16\n        x = self.layer2(x) #16*16 --> 8*8\n        x = self.layer3(x) #8*8 --> 4*4\n        x = self.fc(x)\n        return x\n    \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x\n    \n# 完全就是把ResNet的decoder部分拿了过来\nclass Auxiliary(nn.Module):\n    def __init__(self):\n        super().__init__()\n#         self.fcd = nn.Sequential(\n            \n#         )\n        self.decoder = nn.Sequential(\n            nn.Linear(48, 48*6*6),\n            nn.ReLU(),\n            nn.Unflatten(1, (48,6,6)),\n\t\t\tnn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),\n            nn.ReLU(),\n\t\t\tnn.ConvTranspose2d(24, 12, 4, stride=2, padding=1), \n            nn.ReLU(),\n            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),\n            nn.Tanh(),\n        )\n        \n    def forward(self, x):\n#         x = self.fcd(x)\n        return self.decoder(x)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T06:57:40.661125Z","iopub.execute_input":"2023-05-19T06:57:40.661581Z","iopub.status.idle":"2023-05-19T06:57:40.691545Z","shell.execute_reply.started":"2023-05-19T06:57:40.661540Z","shell.execute_reply":"2023-05-19T06:57:40.690439Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision.models as models\nimport torch.optim.lr_scheduler as lr_scheduler\n# Training hyperparameters\nnum_epochs = 100\nbatch_size = 64\nlearning_rate = 8e-4\n\n# Build training dataloader\nx = torch.from_numpy(train)\ntrain_dataset = CustomTensorDataset(x)\n\ntrain_sampler = RandomSampler(train_dataset)\ntrain_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n\n# Model\nmodel_type = 'fcn'   # selecting a model type from {'cnn', 'fcn', 'vae', 'resnet'}\nmodel_type2 = 'fcn'\nmodel_type3 = 'cnn'\nmodel_classes = {'fcn': fcn_autoencoder(), 'cnn': conv_autoencoder(), 'vae': VAE(), 'resnet' : ResNet() }\nmodel = model_classes[model_type].to('cuda')\nmodel2 = model_classes[model_type2].to('cuda')\nmodel3 = model_classes[model_type3].to('cuda')\nmodels = [model, model2, model3]\n\naux = Auxiliary().to('cuda')\n\n# Loss and optimizer\ncriterion = nn.MSELoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = 5e-4)\noptimizer2 = torch.optim.AdamW(model2.parameters(), lr=learning_rate, weight_decay = 1e-3)\noptimizer3 = torch.optim.Adam(model3.parameters(), lr=learning_rate)\noptimizer_a = torch.optim.AdamW(aux.parameters(), lr=learning_rate, weight_decay = 5e-4)\noptimizers = [optimizer, optimizer2, optimizer3]\nscheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = 4, T_mult = 2, eta_min = learning_rate/20)\nscheduler_a = lr_scheduler.CosineAnnealingWarmRestarts(optimizer_a, T_0 = 2, T_mult = 2,eta_min = learning_rate/20)","metadata":{"id":"in7yLfmqtZTk","execution":{"iopub.status.busy":"2023-05-19T06:57:44.660509Z","iopub.execute_input":"2023-05-19T06:57:44.667933Z","iopub.status.idle":"2023-05-19T06:57:44.920809Z","shell.execute_reply.started":"2023-05-19T06:57:44.667883Z","shell.execute_reply":"2023-05-19T06:57:44.919656Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Training loop","metadata":{"id":"wyooN-JPm8sS"}},{"cell_type":"code","source":"","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_loss = np.inf\n# model.to('cuda')\nmodel.train()\n\naux.train()\nqqdm_train = qqdm(range(num_epochs), desc=format_str('bold', 'Description'))\nfor epoch in qqdm_train:\n    tot_loss = list()\n    tot_loss_a = list()\n    for data in train_dataloader:\n        temperature = epoch // 2 + 1\n        # ===================loading=====================\n        img = data.float().cuda()\n        if model_type in ['fcn']:\n            img = img.view(img.shape[0], -1)\n        \n\n        # ===================forward=====================\n        output = model(img)\n        if model_type in ['vae']:\n            loss = loss_vae(output[0], img, output[1], output[2], criterion)\n        else:\n            loss = criterion(output, img)\n        \n        tot_loss.append(loss.item())\n        # ===================backward====================\n#         torch.autograd.set_detect_anomaly(True)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        #====================new=========================\n#         model.eval()\n#         z = model.encoder(img).detach_()\n    \n#         output = output.detach_()\n#         output_a = aux(z)\n#         loss_a = (criterion(output_a, output).mul(temperature).exp())*criterion(output_a, img)\n#         tot_loss_a.append(loss_a)\n#         optimizer_a.zero_grad()\n#         loss_a.backward()\n#         optimizer_a.step()\n    scheduler.step()\n#     scheduler_a.step()\n    # ===================save_best====================\n    mean_loss = np.mean(tot_loss)\n    if mean_loss < best_loss:\n        best_loss = mean_loss\n        torch.save(model, 'best_model_{}.pt'.format(model_type))\n#         torch.save(aux, 'best_model_{}.pt'.format('aux'))\n    # ===================log========================\n    qqdm_train.set_infos({\n        'epoch': f'{epoch + 1:.0f}/{num_epochs:.0f}',\n        'loss': f'{mean_loss:.4f}',\n    })\n    # ===================save_last========================\n    torch.save(model, 'last_model_{}.pt'.format(model_type))\n#     torch.save(aux, 'la÷st_model_{}.pt'.format('aux'))","metadata":{"id":"JoW1UrrxgI_U","outputId":"78a74d89-0605-4e57-d99c-f86cf110cda4","execution":{"iopub.status.busy":"2023-05-19T06:48:35.413973Z","iopub.execute_input":"2023-05-19T06:48:35.414755Z","iopub.status.idle":"2023-05-19T06:48:36.828104Z","shell.execute_reply.started":"2023-05-19T06:48:35.414712Z","shell.execute_reply":"2023-05-19T06:48:36.826018Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":" \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m                                               \n \u001b[99m0/\u001b[93m100\u001b[0m\u001b[0m  \u001b[99m        -        \u001b[0m  \u001b[99m   -    \u001b[0m                                             \n\u001b[1mDescription\u001b[0m   0.0% |                                                           |/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64, 3, 48, 48])) that is different to the input size (torch.Size([64, 3, 64, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n  return F.mse_loss(input, target, reduction=self.reduction)\n\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m    \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m                                               \n \u001b[99m0/\u001b[93m100\u001b[0m\u001b[0m  \u001b[99m        -        \u001b[0m  \u001b[99m   -    \u001b[0m                                             \n\u001b[1mDescription\u001b[0m   0.0% |                                                           |","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3023983147.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_vae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtot_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3289\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3291\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3292\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (48) at non-singleton dimension 3"],"ename":"RuntimeError","evalue":"The size of tensor a (64) must match the size of tensor b (48) at non-singleton dimension 3","output_type":"error"}]},{"cell_type":"code","source":"# best_loss = np.inf\n# model2.train()\n# # aux.train()\n# num_epochs = 240\n# qqdm_train = qqdm(range(num_epochs), desc=format_str('bold', 'Description'))\n# learning_rate = 8e-4\n# scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer2, T_0 = 3, T_mult = 2)\n# for epoch in qqdm_train:\n#     tot_loss = list()\n#     tot_loss_a = list()\n#     for data in train_dataloader:\n#         temperature = epoch // 2 + 1\n#         # ===================loading=====================\n#         img = data.float().cuda()\n#         if model_type2 in ['fcn']:\n#             img = img.view(img.shape[0], -1)\n        \n\n#         # ===================forward=====================\n#         output = model2(img)\n#         if model_type2 in ['vae']:\n#             loss = loss_vae(output[0], img, output[1], output[2], criterion)\n#         else:\n#             loss = criterion(output, img)\n\n#         tot_loss.append(loss.item())\n#         # ===================backward====================\n#         optimizer2.zero_grad()\n#         loss.backward()\n#         optimizer2.step()\n#         #====================new=========================\n# #         model.eval()\n# #         z = model.encoder(img).detach_()\n# #         output = output.detach_()\n# #         output_a = aux(z)\n# #         loss_a = (criterion(output_a, output).mul(temperature).exp())*criterion(output_a, img)\n# #         tot_loss_a.append(loss_a)\n# #         optimizer_a.zero_grad()\n# #         loss_a.backward()\n# # #         optimizer_a.step()\n#     scheduler.step()\n#     # ===================save_best====================\n#     mean_loss = np.mean(tot_loss)\n#     if mean_loss < best_loss:\n#         best_loss = mean_loss\n#         torch.save(model2, 'best_model_{}.pt'.format(model_type2))\n# #         torch.save(aux, 'best_model_{}.pt'.format('aux'))\n#     # ===================log========================\n#     qqdm_train.set_infos({\n#         'epoch': f'{epoch + 1:.0f}/{num_epochs:.0f}',\n#         'loss': f'{mean_loss:.4f}',\n#     })\n#     # ===================save_last========================\n#     torch.save(model2, 'last_model_{}.pt'.format(model_type2))","metadata":{"execution":{"iopub.status.busy":"2023-05-19T06:45:04.445108Z","iopub.status.idle":"2023-05-19T06:45:04.446077Z","shell.execute_reply.started":"2023-05-19T06:45:04.445789Z","shell.execute_reply":"2023-05-19T06:45:04.445820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# best_loss = np.inf\n# model3.train()\n# # aux.train()\n# num_epochs = 80\n# qqdm_train = qqdm(range(num_epochs), desc=format_str('bold', 'Description'))\n# scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer3, T_0 = 2, T_mult = 2)\n# for epoch in qqdm_train:\n#     tot_loss = list()\n#     tot_loss_a = list()\n#     for data in train_dataloader:\n#         temperature = epoch // 2 + 1\n#         # ===================loading=====================\n#         img = data.float().cuda()\n#         if model_type3 in ['fcn']:\n#             img = img.view(img.shape[0], -1)\n        \n\n#         # ===================forward=====================\n#         output = model3(img)\n#         if model_type3 in ['vae']:\n#             loss = loss_vae(output[0], img, output[1], output[2], criterion)\n#         else:\n#             loss = criterion(output, img)\n\n#         tot_loss.append(loss.item())\n#         # ===================backward====================\n#         optimizer3.zero_grad()\n#         loss.backward()\n#         optimizer3.step()\n#         #====================new=========================\n# #         model.eval()\n# #         z = model.encoder(img).detach_()\n# #         output = output.detach_()\n# #         output_a = aux(z)\n# #         loss_a = (criterion(output_a, output).mul(temperature).exp())*criterion(output_a, img)\n# #         tot_loss_a.append(loss_a)\n# #         optimizer_a.zero_grad()\n# #         loss_a.backward()\n# # #         optimizer_a.step()\n#     scheduler.step()\n#     # ===================save_best====================\n#     mean_loss = np.mean(tot_loss)\n#     if mean_loss < best_loss:\n#         best_loss = mean_loss\n#         torch.save(model3, 'best_model_{}.pt'.format(model_type3))\n# #         torch.save(aux, 'best_model_{}.pt'.format('aux'))\n#     # ===================log========================\n#     qqdm_train.set_infos({\n#         'epoch': f'{epoch + 1:.0f}/{num_epochs:.0f}',\n#         'loss': f'{mean_loss:.4f}',\n#     })\n#     # ===================save_last========================\n#     torch.save(model3, 'last_model_{}.pt'.format(model_type3))","metadata":{"execution":{"iopub.status.busy":"2023-05-19T06:45:04.447776Z","iopub.status.idle":"2023-05-19T06:45:04.448531Z","shell.execute_reply.started":"2023-05-19T06:45:04.448229Z","shell.execute_reply":"2023-05-19T06:45:04.448260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classifier","metadata":{}},{"cell_type":"markdown","source":"# Inference\nModel is loaded and generates its anomaly score predictions.","metadata":{"id":"Wk0UxFuchLzR"}},{"cell_type":"markdown","source":"## Initialize\n- dataloader\n- model\n- prediction file","metadata":{"id":"evgMW3OwoGqD"}},{"cell_type":"code","source":"eval_batch_size = 1024\n\n# build testing dataloader\ndata = torch.tensor(test, dtype=torch.float32)\ntest_dataset = CustomTensorDataset(data)\ntest_sampler = SequentialSampler(test_dataset)\ntest_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=eval_batch_size, num_workers=1)\neval_loss = nn.MSELoss(reduction='none')\n\n# load trained model\ncheckpoint_path = f'last_model_{model_type}.pt'\ncheckpoint_path2 = f'last_model_{model_type2}.pt'\ncheckpoint_path3 = f'last_model_{model_type3}.pt'\n# checkpoint_path = '/kaggle/input/hw8-pt/ml2023spring-hw8/best_model_resnet.pt'\ncheckpoint_path_a = 'last_model_aux.pt'\n# checkpoint_path = '/kaggle/input/hw-model/best_model_cnn-2pt'\nmodel = torch.load(checkpoint_path)\nmodel.eval()\n# aux = Auxiliary().to('cuda')\n# aux = torch.load(checkpoint_path_a)\n# model2 = torch.load(checkpoint_path2)\n# model2.eval()\n# model3 = torch.load(checkpoint_path3)\n# model3.eval()\n# aux = torch.load(checkpoint_path_a)\n# aux.eval()\n# prediction file \nout_file = '/kaggle/working/prediction.csv'\nout_file_a = '/kaggle/working/prediction_a.csv'","metadata":{"id":"_MBnXAswoKmq","execution":{"iopub.status.busy":"2023-05-19T06:58:26.912829Z","iopub.execute_input":"2023-05-19T06:58:26.913819Z","iopub.status.idle":"2023-05-19T06:58:27.316846Z","shell.execute_reply.started":"2023-05-19T06:58:26.913777Z","shell.execute_reply":"2023-05-19T06:58:27.315728Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"_1IxCX2iCW6V","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"anomality = []\nauxs = []\nwith torch.no_grad():\n    for i, data in enumerate(test_dataloader):\n        img = data.float().to('cuda')\n        z = model.encoder(img)\n        output = model(img)   \n#         output, output_a = model.decoder(z), aux(z)\n        loss = eval_loss(output, img[:, 0:24, :, :]).mean([1, 2, 3])\n#         loss_a = eval_loss(output_a, img).mean([1, 2, 3])\n        anomality.append(loss)\n#         auxs.append(loss_a)\n        \nanomality = torch.cat(anomality, axis=0)\nanomality = torch.sqrt(anomality).reshape(len(test), 1).cpu().numpy()\n# auxs = torch.cat(auxs, axis=0)\n# auxs = torch.sqrt(auxs).reshape(len(test), 1).cpu().numpy()\n \ndf = pd.DataFrame(anomality, columns=['score'])\ndf.to_csv(out_file, index_label = 'ID')\n# df_a = pd.DataFrame(auxs, columns=['score'])\n# df_a.to_csv(out_file_a, index_label = 'ID')\n# anomality_ = []\n# for i in range(0, len(anomality)):\n#     anomality_.append((anomality[i]+auxs[i])/2)\n# df = pd.DataFrame(anomality_, columns=['score'])\n# df.to_csv('/kaggle/working/prediction_sum.csv', index_label = 'ID')\n# df = pd.DataFrame(auxs, columns=['score'])\n# df.to_csv(out_file_a, index_label = 'ID')\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-05-19T06:58:50.148743Z","iopub.execute_input":"2023-05-19T06:58:50.149852Z","iopub.status.idle":"2023-05-19T06:58:51.857272Z","shell.execute_reply.started":"2023-05-19T06:58:50.149809Z","shell.execute_reply":"2023-05-19T06:58:51.856015Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# anomality_ = []\n# for i in range(0, len(anomality)):\n#     anomality_.append((anomality[i]+anomality2[i]+anomality3[i])/3)\n# df = pd.DataFrame(anomality_, columns=['score'])\n# df.to_csv('/kaggle/working/prediction_sum.csv', index_label = 'ID')\n# # df = pd.DataFrame(auxs, columns=['score'])\n# # df.to_csv(out_file_a, index_label = 'ID')","metadata":{"execution":{"iopub.status.busy":"2023-05-19T06:45:04.455741Z","iopub.status.idle":"2023-05-19T06:45:04.456331Z","shell.execute_reply.started":"2023-05-19T06:45:04.456006Z","shell.execute_reply":"2023-05-19T06:45:04.456035Z"},"trusted":true},"execution_count":null,"outputs":[]}]}